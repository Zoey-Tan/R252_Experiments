{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn8UhmbQexvt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "import seaborn as sns\n",
        "import torch.nn.init as init\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "yY7tOj442fQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "KDgsf4BgjKU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "S61VZ6XR2kFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "    EPS = 1e-6\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        #imgs, targets = next(train_loader)\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        output = model(imgs)\n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()\n",
        "\n",
        "        # Freezing Pruned weights by making their gradients Zero\n",
        "        for name, p in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                tensor = p.data\n",
        "                grad_tensor = p.grad\n",
        "                grad_tensor = torch.where(tensor.abs() < EPS, torch.zeros_like(grad_tensor), grad_tensor)\n",
        "                p.grad.data = grad_tensor\n",
        "        optimizer.step()\n",
        "    return train_loss.item()\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "G6PdfPJNjMrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_nonzeros(model, verbose= False):\n",
        "    nonzero = total = 0\n",
        "    for name, p in model.named_parameters():\n",
        "        tensor = p.data.cpu().numpy()\n",
        "        nz_count = np.count_nonzero(tensor)\n",
        "        total_params = np.prod(tensor.shape)\n",
        "        nonzero += nz_count\n",
        "        total += total_params\n",
        "        if verbose:\n",
        "            print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
        "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')\n",
        "    return np.round((nonzero/total)*100,1)"
      ],
      "metadata": {
        "id": "MUkz9fQG200e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_init(m):\n",
        "    '''\n",
        "    Usage:\n",
        "        model = Model()\n",
        "        model.apply(weight_init)\n",
        "    '''\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)"
      ],
      "metadata": {
        "id": "lDLISJaGzIfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mask(model):\n",
        "    global mask\n",
        "    count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            count += 1\n",
        "    mask = [None]* count\n",
        "    count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            mask[count] = np.ones_like(tensor)\n",
        "            count += 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "QXOT2JGJ0at6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def original_initialization(mask_current, rewinding_state_dict):\n",
        "    global model\n",
        "    count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            weight_dev = param.device\n",
        "            param.data = torch.from_numpy(mask_current[count] * rewinding_state_dict[name].cpu().numpy()).to(weight_dev)\n",
        "            count += 1\n",
        "        if \"bias\" in name:\n",
        "            param.data = rewinding_state_dict[name]"
      ],
      "metadata": {
        "id": "DmTTehmq01in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkdir(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)"
      ],
      "metadata": {
        "id": "_6IKSnZQ2fkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_by_percentile_fixed_all_layer(percentage):\n",
        "      global mask\n",
        "      global model\n",
        "\n",
        "      count = 0\n",
        "      for name, param in model.named_parameters():\n",
        "          if 'weight' in name:\n",
        "              tensor = param.data.cpu().numpy()\n",
        "              alive = tensor[np.nonzero(tensor)] # flattened array of nonzero values\n",
        "              percentile_value = np.percentile(abs(alive), percentage)\n",
        "              # Convert Tensors to numpy and calculate\n",
        "              weight_dev = param.device\n",
        "              new_mask = np.where(abs(tensor) < percentile_value, 0, mask[count])\n",
        "              # Apply new weight and mask\n",
        "              param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
        "              mask[count] = new_mask\n",
        "              count += 1"
      ],
      "metadata": {
        "id": "BY-sn8962hk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_by_percentile_fixed_per_layer(percentages):\n",
        "      global mask\n",
        "      global model\n",
        "\n",
        "      count = 0\n",
        "      for name, param in model.named_parameters():\n",
        "          if 'weight' in name:\n",
        "              tensor = param.data.cpu().numpy()\n",
        "              alive = tensor[np.nonzero(tensor)] # flattened array of nonzero values\n",
        "              percentile_value = np.percentile(abs(alive), percentages[count])\n",
        "              # Convert Tensors to numpy and calculate\n",
        "              weight_dev = param.device\n",
        "              new_mask = np.where(abs(tensor) < percentile_value, 0, mask[count])\n",
        "              # Apply new weight and mask\n",
        "              param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
        "              mask[count] = new_mask\n",
        "              count += 1"
      ],
      "metadata": {
        "id": "mYT2ceiebHBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_global_taylor_threshold(percentage):\n",
        "    global model\n",
        "    global mask\n",
        "    weights = {}\n",
        "    gradients = {}\n",
        "    count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            weights[name] = param.data.cpu().numpy()\n",
        "            if name == \"bn1.weight\":\n",
        "                print(name, weights[name])\n",
        "            gradients[name] = param.grad.cpu().numpy()\n",
        "            if name == \"bn1.weight\":\n",
        "                print(name, gradients[name])\n",
        "            gradients[name] = gradients[name][np.nonzero(weights[name])]\n",
        "            if name == \"bn1.weight\":\n",
        "                print(name, gradients[name])\n",
        "            weights[name] = weights[name][np.nonzero(weights[name])]\n",
        "            if name == \"bn1.weight\":\n",
        "                print(name, weights[name])\n",
        "\n",
        "    flattened_first_order = []\n",
        "    for name in weights.keys():\n",
        "        flattened_first_order.append(np.abs(weights[name].flatten()*gradients[name].flatten()))\n",
        "        if name == \"bn1.weight\":\n",
        "            print(np.abs(weights[name].flatten()*gradients[name].flatten()))\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    threshold = np.percentile(np.concatenate(flattened_first_order), percentage)\n",
        "    return threshold"
      ],
      "metadata": {
        "id": "SpsbMwT75ZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_by_percentile_global_taylor(percentage):\n",
        "      global mask\n",
        "      global model\n",
        "\n",
        "      count = 0\n",
        "      threshold = compute_global_taylor_threshold(percentage)\n",
        "      print(threshold)\n",
        "      for name, param in model.named_parameters():\n",
        "          if 'weight' in name:\n",
        "              tensor = param.data.cpu().numpy()\n",
        "              gradient = param.grad.cpu().numpy()\n",
        "              weight_dev = param.device\n",
        "              new_mask = np.where(abs(tensor*gradient) < threshold, 0, mask[count])\n",
        "              param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
        "              mask[count] = new_mask\n",
        "              count += 1"
      ],
      "metadata": {
        "id": "Hj5Qvk9y8iFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils import prune\n",
        "def l1_channel_pruning(round):\n",
        "    global mask\n",
        "    global model\n",
        "\n",
        "    config = {\"conv1\": 1-0.95**round,\n",
        "        \"layer1.0.conv1\": 1-(1-0.1*(1.05**0))**round,\n",
        "        \"layer1.0.conv2\": 1-(1-0.1*(1.05**1))**round,\n",
        "        \"layer1.1.conv1\": 1-(1-0.1*(1.05**2))**round,\n",
        "        \"layer1.1.conv2\": 1-(1-0.1*(1.05**3))**round,\n",
        "        \"layer2.0.conv1\": 1-(1-0.1*(1.05**4))**round,\n",
        "        \"layer2.0.conv2\": 1-(1-0.1*(1.05**5))**round,\n",
        "        \"layer2.0.shortcut.0\": 1-0.95**round,\n",
        "        \"layer2.1.conv1\": 1-(1-0.1*(1.05**6))**round,\n",
        "        \"layer2.1.conv2\": 1-(1-0.1*(1.05**7))**round,\n",
        "        \"layer3.0.conv1\": 1-(1-0.1*(1.05**8))**round,\n",
        "        \"layer3.0.conv2\": 1-(1-0.1*(1.05**9))**round,\n",
        "        \"layer3.0.shortcut.0\": 1-0.95**round,\n",
        "        \"layer3.1.conv1\": 1-(1-0.1*(1.05**10))**round,\n",
        "        \"layer3.1.conv2\": 1-(1-0.1*(1.05**11))**round,\n",
        "        \"layer4.0.conv1\": 1-(1-0.1*(1.05**12))**round,\n",
        "        \"layer4.0.conv2\": 1-(1-0.1*(1.05**13))**round,\n",
        "        \"layer4.0.shortcut.0\": 1-0.85**round,\n",
        "        \"layer4.1.conv1\": 1-(1-0.1*(1.05**14))**round,\n",
        "        \"layer4.1.conv2\": 1-(1-0.1*(1.05**15))**round }\n",
        "\n",
        "    count = 0\n",
        "    for module_name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            prune.ln_structured(module, name=\"weight\", amount=config[module_name], n = 1, dim = 0)\n",
        "            prune.remove(module, 'weight')\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            weight_dev = param.device\n",
        "            new_mask = np.where(abs(tensor) == 0, 0, mask[count])\n",
        "            mask[count] = new_mask\n",
        "            count += 1"
      ],
      "metadata": {
        "id": "A8euBy9mKJdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_channel_pruning(round):\n",
        "    global mask\n",
        "    global model\n",
        "\n",
        "    count = 0\n",
        "    for module_name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            prune.ln_structured(module, name=\"weight\", amount=1-0.8**round, n = 2, dim = 0)\n",
        "            prune.remove(module, 'weight')\n",
        "        elif isinstance(module, torch.nn.Linear) and (not module_name == \"linear\"):\n",
        "            prune.ln_structured(module, name=\"weight\", amount=1-0.8**round, n = 2, dim = 0)\n",
        "            prune.remove(module, 'weight')\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            weight_dev = param.device\n",
        "            new_mask = np.where(abs(tensor) == 0, 0, mask[count])\n",
        "            mask[count] = new_mask\n",
        "            count += 1"
      ],
      "metadata": {
        "id": "fNY7XVIKXZKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.ao.pruning._experimental.pruner import FPGMPruner, SaliencyPruner\n",
        "import torch.nn.utils.parametrize as parametrize\n",
        "\n",
        "def FPGM_pruning(round):\n",
        "    global model\n",
        "    global mask\n",
        "\n",
        "    pruner = FPGMPruner(1-0.8**round)\n",
        "    config = [\n",
        "        {\"tensor_fqn\": \"conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer1.0.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer1.0.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer1.1.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer1.1.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer2.0.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer2.0.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer2.0.shortcut.0.weight\"},\n",
        "        {\"tensor_fqn\": \"layer2.1.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer2.1.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer3.0.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer3.0.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer3.0.shortcut.0.weight\"},\n",
        "        {\"tensor_fqn\": \"layer3.1.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer3.1.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer4.0.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer4.0.conv2.weight\"},\n",
        "        {\"tensor_fqn\": \"layer4.0.shortcut.0.weight\"},\n",
        "        {\"tensor_fqn\": \"layer4.1.conv1.weight\"},\n",
        "        {\"tensor_fqn\": \"layer4.1.conv2.weight\"}]\n",
        "\n",
        "    pruner.prepare(model, config)\n",
        "    pruner.enable_mask_update = True\n",
        "    pruner.step()\n",
        "    for module_name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            try:\n",
        "                parametrize.remove_parametrizations(module, \"weight\")\n",
        "            except:\n",
        "                pass\n",
        "    count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            weight_dev = param.device\n",
        "            new_mask = np.where(abs(tensor) == 0, 0, mask[count])\n",
        "            mask[count] = new_mask\n",
        "            count += 1"
      ],
      "metadata": {
        "id": "2Lu2TOSRYzmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mask_size(mask):\n",
        "  total = 0\n",
        "  for layer in mask:\n",
        "      total += len(layer.flatten())\n",
        "  return total\n",
        "\n",
        "def compute_mask_sum(mask):\n",
        "  total = 0\n",
        "  for layer in mask:\n",
        "      total += layer.flatten().sum()\n",
        "  return total"
      ],
      "metadata": {
        "id": "IDRGFLzg_VvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = ResNet18()\n",
        "model = model.to(device)\n",
        "model.apply(weight_init)\n",
        "compute_nonzeros(model)\n",
        "make_mask(model)\n",
        "iterative_pruning_rounds = 15\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# One additional round required for the original training\n",
        "for round in range(iterative_pruning_rounds+1):\n",
        "    if not round == 0:\n",
        "        l1_channel_pruning(round)\n",
        "        original_initialization(mask, initial_state_dict)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    #print(f\"\\n--- Pruning Level [{ITE}:{_ite}/{ITERATION}]: ---\")\n",
        "    print(\"_________round\", round, \"_________\")\n",
        "\n",
        "    p_m_current = compute_nonzeros(model, verbose=True)\n",
        "    print(compute_mask_size(mask), compute_mask_sum(mask)/compute_mask_size(mask))\n",
        "\n",
        "    for epoch in [1]:\n",
        "        loss = train(model, train_loader, optimizer, criterion)\n",
        "    #_ = compute_nonzeros(model, verbose=True)\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "id": "y9DUbhCDmrDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments"
      ],
      "metadata": {
        "id": "nvOqUatj2yEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128\n",
        "training_epochs = 160\n",
        "target_p_m = 10\n",
        "iterative_pruning_rounds = 15\n",
        "pruning_rate_per_round = 20 #(1-np.power(target_p_m/100, 1/iterative_pruning_rounds))*100\n",
        "reinit = False\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "5da7M30VKZSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=128, shuffle=False)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "model = ResNet18().to(device)\n",
        "model.apply(weight_init)\n",
        "\n",
        "initial_state_dict = copy.deepcopy(model.state_dict())\n",
        "experiment_path = f\"/content/drive/MyDrive/R252/Structured_l1_large/\"\n",
        "checkdir(experiment_path+\"saves/\")\n",
        "torch.save(model, experiment_path+\"saves/initial_state_dict.pth.tar\")\n",
        "make_mask(model)\n",
        "print(compute_mask_size(mask), compute_mask_sum(mask)/compute_mask_size(mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIrbEeQUlbN0",
        "outputId": "0c83c91d-9d7f-43f6-8a91-49a90e82c761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "11169152 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())\n",
        "\n",
        "best_accuracy_per_round_history = np.zeros(iterative_pruning_rounds+1,float)\n",
        "best_accuracy_per_round = 0.0\n",
        "best_accuracy_epoch = 0\n",
        "p_m = np.zeros(iterative_pruning_rounds+1,float)\n",
        "step = 0\n",
        "loss_history = np.zeros(training_epochs,float)\n",
        "accuracy_history = np.zeros(training_epochs+1,float)\n",
        "_ = compute_nonzeros(model)\n",
        "# One additional round required for the original training\n",
        "for round in range(iterative_pruning_rounds+1):\n",
        "    if not round == 0:\n",
        "        l1_channel_pruning(round)\n",
        "        if reinit:\n",
        "            model.apply(weight_init)\n",
        "            step = 0\n",
        "            for name, param in model.named_parameters():\n",
        "                if 'weight' in name:\n",
        "                    weight_dev = param.device\n",
        "                    param.data = torch.from_numpy(param.data.cpu().numpy() * mask[step]).to(weight_dev)\n",
        "                    step = step + 1\n",
        "            step = 0\n",
        "        else:\n",
        "            original_initialization(mask, rewinding_state_dict)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "    #print(f\"\\n--- Pruning Level [{ITE}:{_ite}/{ITERATION}]: ---\")\n",
        "    print(\"_________round\", round, \"_________\")\n",
        "\n",
        "    p_m_current = compute_nonzeros(model, verbose=False)\n",
        "    print(compute_mask_size(mask), compute_mask_sum(mask)/compute_mask_size(mask))\n",
        "\n",
        "    p_m[round] = p_m_current\n",
        "    pbar = tqdm(range(training_epochs))\n",
        "\n",
        "    accuracy = test(model, test_loader, criterion)\n",
        "    best_accuracy_per_round = accuracy\n",
        "    accuracy_history[0] = accuracy\n",
        "\n",
        "    for epoch in pbar:\n",
        "        if epoch >= 80:\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = 0.01\n",
        "        elif epoch >= 120:\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = 0.001\n",
        "        loss = train(model, train_loader, optimizer, criterion)\n",
        "\n",
        "\n",
        "        accuracy = test(model, test_loader, criterion)\n",
        "\n",
        "        if accuracy > best_accuracy_per_round:\n",
        "            best_accuracy_per_round = accuracy\n",
        "            best_accuracy_epoch = epoch\n",
        "            checkdir(experiment_path+\"saves/\")\n",
        "            torch.save(model, experiment_path+f\"saves/round_{round}_best_model_lt.pth.tar\")\n",
        "\n",
        "        if round == 0 and epoch == 9:\n",
        "            checkdir(experiment_path+\"saves/\")\n",
        "            torch.save(model, experiment_path+f\"saves/rewinding_state_dict_1.pth.tar\")\n",
        "            rewinding_state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        if round == 0 and epoch == 15:\n",
        "            checkdir(experiment_path+\"saves/\")\n",
        "            torch.save(model, experiment_path+f\"saves/rewinding_state_dict_2.pth.tar\")\n",
        "\n",
        "        loss_history[epoch] = loss\n",
        "        accuracy_history[epoch+1] = accuracy\n",
        "        pbar.set_description(\n",
        "                f'Train Epoch: {epoch}/{training_epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}% Best Accuracy: {best_accuracy_per_round:.2f}% (Epoch:{best_accuracy_epoch})')\n",
        "\n",
        "    checkdir(experiment_path+\"saves/\")\n",
        "    torch.save(model, experiment_path+f\"saves/round_{round}_final_model_lt.pth.tar\")\n",
        "\n",
        "    _ = compute_nonzeros(model, verbose=False)\n",
        "\n",
        "    best_accuracy_per_round_history[round] = best_accuracy_per_round\n",
        "\n",
        "    # Plotting Loss (Training), Accuracy (Testing) per Epoch\n",
        "    plt.plot(np.arange(1,(training_epochs)+1), 100*(loss_history - np.min(loss_history))/np.ptp(loss_history).astype(float), c=\"blue\", label=\"Loss\")\n",
        "    plt.plot(np.arange(1,(training_epochs)+1), accuracy_history[1:], c=\"red\", label=\"Accuracy\")\n",
        "    plt.title(f\"Loss and Accuracy per Epoch (ResNet18, CIFAR10)\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss and Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(color=\"gray\")\n",
        "    checkdir(experiment_path+\"plots/\")\n",
        "    plt.savefig(experiment_path+f\"plots/round_{round}_LossVsAccuracy_{p_m_current}.png\", dpi=1200)\n",
        "    plt.close()\n",
        "\n",
        "    # Dump Plot values\n",
        "    checkdir(experiment_path+\"dumps/\")\n",
        "    loss_history.dump(experiment_path+f\"dumps/round_{round}_loss_history_{p_m_current}.dat\")\n",
        "    accuracy_history.dump(experiment_path+f\"dumps/round_{round}_accuracy_history_{p_m_current}.dat\")\n",
        "    with open(experiment_path+f\"dumps/round_{round}_mask_{p_m_current}.pkl\", 'wb') as fp:\n",
        "        pickle.dump(mask, fp)\n",
        "\n",
        "    best_accuracy_per_round = 0.0\n",
        "    best_accuracy_epoch\n",
        "    loss_history = np.zeros(training_epochs,float)\n",
        "    accuracy_history = np.zeros(training_epochs+1,float)\n",
        "\n",
        "if iterative_pruning_rounds > 1:\n",
        "    # Dumping Values for Plotting\n",
        "    checkdir(experiment_path+\"dumps/\")\n",
        "    p_m.dump(experiment_path+\"dumps/compression.dat\")\n",
        "    best_accuracy_per_round_history.dump(experiment_path+\"dumps/best_accuracy.dat\")\n",
        "\n",
        "    # Plotting\n",
        "    a = np.arange(iterative_pruning_rounds+1)\n",
        "    plt.plot(a, best_accuracy_per_round_history, c=\"blue\", label=\"Winning tickets\")\n",
        "    plt.title(f\"Test Accuracy vs Unpruned Weights Percentage (ResNet18, CIFAR10)\")\n",
        "    plt.xlabel(\"Unpruned Weights Percentage\")\n",
        "    plt.ylabel(\"test accuracy\")\n",
        "    plt.xticks(a, p_m, rotation =\"vertical\")\n",
        "    plt.ylim(0,100)\n",
        "    plt.legend()\n",
        "    plt.grid(color=\"gray\")\n",
        "    checkdir(experiment_path+\"plots/\")\n",
        "    plt.savefig(experiment_path+\"plots/AccuracyVsWeights.png\", dpi=1200)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "trrk9plMllO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-hM_Nqfc2u_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}